{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eddeaff",
   "metadata": {},
   "source": [
    "# Como fazer chamadas simples com API? \n",
    "\n",
    "Antes de mais nada, vamos escolher o LLM utilizado, seja ele o ChatGPT (gepeto), o Gemini etc. Caso você escolha o gepeto, terá de fazer um **pip install openai**, caso escolha o gemini, terá de fazer **pip install google**. Uma vez escolhido o LLM, cria um ambiente virtual para isolar o ambiente de desenvolvimento do seu código com **python -m venv nome-do-seu-venv** e depois ative-o **.\\nome-do-seu-venv\\Scripts\\Activate.ps1**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c550b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMs\n",
    "from openai import OpenAI\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "# Para validação de campos e geração de uma resposta estruturada\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "import json\n",
    "\n",
    "# Para a leitura das chaves no arquivo \".env\"\n",
    "from dotenv import load_dotenv, dotenv_values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db8397b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Protegendo as chaves de API e carregando-as em variáveis\n",
    "config = dotenv_values(\".env\")\n",
    "openai_api_key = config[\"IRAN_OPENAI_KEY\"]\n",
    "gemini_api_key = config[\"IRAN_GEMINI_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "71c61a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alimentando o client com as devidas chaves de api\n",
    "client_openai = OpenAI(api_key=openai_api_key)\n",
    "client_gemini = genai.Client(api_key=gemini_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ec5d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ambos as funções abaixo possuem o mesmo funcionamento: \n",
    "# 1 - Você passa um contexto/prompt (context)\n",
    "# 2 - Você passa uma pergunta ou qulquer coisa que queira saber (input)\n",
    "# As funções fazem uma chamada simples para os modelos de  LLM e a resposta obtida é retornada como resposta\n",
    "\n",
    "\n",
    "\n",
    "# Função que utiliza a API da OpenAI\n",
    "def response_openai(context:str, input:str) -> str:\n",
    "    response = client_openai.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        instructions=context,\n",
    "        input= input,\n",
    "        temperature=0.5\n",
    "    )\n",
    "    return response.output_text\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Função que utiliza a API do Gemini\n",
    "def response_gemini(context:str, input:str) -> str:\n",
    "        \n",
    "    response = client_gemini.models.generate_content(\n",
    "        model=\"gemini-2.5-flash\", \n",
    "        config=types.GenerateContentConfig(\n",
    "            system_instruction=context,\n",
    "            temperature=0.5),\n",
    "        contents=input\n",
    "    )\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afcf949",
   "metadata": {},
   "source": [
    "### Como obter uma resposta estruturada no formato de JSON? \n",
    "\n",
    "Vamos supor que você quer analisar um processo judicial envolvendo tráfico de drogas de forma rápida e eficiente. Para isso você precisa extrair informações como: \n",
    "- O processo se trata de tráfico de drogas?\n",
    "- Qual o tipo de droga envolvida?\n",
    "- Qual a quantidade do tipo de droga envolvida?\n",
    "- Qual o sexo da pessoa envolvida? \n",
    "- Qual o tipo de pena? \n",
    "- Qual o tempo da pena em meses? \n",
    "\n",
    "Para isso precisaremos utilizar pydantic para garantir uma validação dos campos que devem ser retornados pelo LLM e precisamo mudar um pouquinho a estrutura das nossas funções de chamadas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dfad6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set do tipo de resposta possível do LLM\n",
    "class Escopo(Enum):\n",
    "    SIM = \"sim\"\n",
    "    NAO = \"nao\"\n",
    "\n",
    "\n",
    "class Drogas(BaseModel):\n",
    "    escopo: Escopo\n",
    "    maconha: str\n",
    "    cocaina: str\n",
    "    crack: str\n",
    "    qtd_maconha: float\n",
    "    qtd_cocaina: float\n",
    "    qtd_crack: float\n",
    "    sexo: str\n",
    "    reincidente: str\n",
    "    decisao: str\n",
    "    tipo_pena: str\n",
    "    tempo: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4068cdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classificador_openai(context:str, input:str, estrutura:Drogas) -> dict:\n",
    "    response = client_openai.responses.parse(  # mudar aqui de .create() para .parse()\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        instructions=context,\n",
    "        input=input,\n",
    "        temperature=0.0,\n",
    "        text_format = estrutura # mudar aqui para o schema de classe\n",
    "    )\n",
    "    # mudar aqui de \"response.output_text\" para \"response.output_parsed\"\n",
    "    return response.output_parsed.model_dump()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def clasificador_gemini(prompt:str, input:str, estrutura=Drogas) -> dict:\n",
    "\n",
    "    content = f\"{prompt}\\n\\nProcesso:\\n{input}\"\n",
    "\n",
    "    response = client_gemini.models.generate_content( # mudar aqui de \".generate_content()\" para \".generate_content_stream()\"\n",
    "        model=\"gemini-2.5-flash\",\n",
    "        contents=content,\n",
    "        config={\n",
    "        \"response_mime_type\": \"application/json\",\n",
    "        \"response_json_schema\": estrutura.model_json_schema(),\n",
    "    },  \n",
    "    )\n",
    "\n",
    "    # mudar aqui de \"response.text\" por:\n",
    "    result = response.candidates[0].content.parts[0].text\n",
    "    return result\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d7574806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# É necessário também um bom prompt para garantir a saída de uma resposta que segue a estrutura que nós buscamos\n",
    "\n",
    "prompt_otimizado = \"\"\"\n",
    "Você é um assistente de inteligência artificial que auxilia na anotação de sentenças judiciais do Tribunal de Justiça de São Paulo em processos envolvendo tráfico de drogas.\n",
    "\n",
    "Você receberá o texto da sentença e deverá retornar um arquivo JSON, seguindo as regras abaixo:\n",
    "\n",
    "- O processo faz parte do escopo da pesquisa? O caso deve: Ser um caso relacionado a tráfico de drogas; Envolver porte de maconha, crack ou cocaína; Envolver apenas uma pessoa acusada.\n",
    "- Quantidade de maconha em gramas: Preencha apenas os números. Coloque 0 se o caso não envolve essa droga. Use \",\" como separador decimal. Se a decisão não menciona a quantidade em gramas, faça a conversão, seguindo a regra: 1 porção = 2 gramas.\n",
    "- Quantidade de cocaína em gramas: Preencha apenas os números. Coloque 0 se o caso não envolve essa droga. Use \",\" como separador decimal. Se a decisão não menciona a quantidade em gramas, faça a conversão, seguindo a regra: 1 porção ou pino = 0,5 grama.\n",
    "- Quantidade de crack em gramas: Preencha apenas os números. Coloque 0 se o caso não envolve essa droga. Use \",\" como separador decimal. Se a decisão não menciona a quantidade em gramas, faça a conversão, seguindo a regra: 1 porção = 0,1 grama.\n",
    "- Decisão: pode ser procedente (condenação), improcedente / punibilidade extinta, ou parcialmente procedente / advertência.\n",
    "- Tipo de pena: pode ser fechado, semiaberto ou aberto.\n",
    "- Tempo da pena (em meses): Preencha apenas os números. Converta o tempo em meses. Por exemplo, 2 anos e 7 meses = 31 meses.\n",
    "\n",
    "Retorne um arquivo JSON com as seguintes informações:\n",
    "\n",
    "{\n",
    " \"escopo\": \"sim/não\",\n",
    " \"maconha\": \"sim/não\",\n",
    " \"cocaina\": \"sim/não\",\n",
    " \"crack\": \"sim/não\",\n",
    " \"qtd_maconha\": 0,\n",
    " \"qtd_cocaina\": 0,\n",
    " \"qtd_crack\": 0,\n",
    " \"sexo\": \"masculino/feminino/não informado\",\n",
    " \"reincidente\": \"sim/não/não informado\",\n",
    " \"decisao\": \"procedente/improcedente/parcialmente procedente\",\n",
    " \"tipo_pena\": \"fechado/semiaberto/aberto\",\n",
    " \"tempo\": 0\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0657d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"escopo\": \"sim\",\n",
      " \"maconha\": \"sim\",\n",
      " \"cocaina\": \"nao\",\n",
      " \"crack\": \"nao\",\n",
      " \"qtd_maconha\": 98.13,\n",
      " \"qtd_cocaina\": 0,\n",
      " \"qtd_crack\": 0,\n",
      " \"sexo\": \"feminino\",\n",
      " \"reincidente\": \"não informado\",\n",
      " \"decisao\": \"parcialmente procedente\",\n",
      " \"tipo_pena\": \"aberto\",\n",
      " \"tempo\": 0\n",
      "}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8dff3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'escopo': <Escopo.SIM: 'sim'>, 'maconha': 'sim', 'cocaina': 'nao', 'crack': 'nao', 'qtd_maconha': 98.13, 'qtd_cocaina': 0.0, 'qtd_crack': 0.0, 'sexo': 'feminino', 'reincidente': 'nao informado', 'decisao': 'procedente', 'tipo_pena': 'nao informado', 'tempo': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print(saida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8c69e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e0aff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
